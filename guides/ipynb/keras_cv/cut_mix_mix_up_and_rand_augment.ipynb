{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# CutMix, MixUp, and RandAugment image augmentation with KerasCV\n",
    "\n",
    "**Author:** [lukewood](https://lukewood.xyz)<br>\n",
    "**Date created:** 2022/04/08<br>\n",
    "**Last modified:** 2022/04/08<br>\n",
    "**Description:** Use KerasCV to augment images with CutMix, MixUp, RandAugment, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Overview\n",
    "\n",
    "KerasCV makes it easy to assemble state-of-the-art, industry-grade data augmentation\n",
    "pipelines for image classification and object detection tasks. KerasCV offers a wide\n",
    "suite of preprocessing layers implementing common data augmentation techniques.\n",
    "\n",
    "Perhaps three of the most useful layers are `keras_cv.layers.CutMix`,\n",
    "`keras_cv.layers.MixUp`, and `keras_cv.layers.RandAugment`. These\n",
    "layers are used in nearly all state-of-the-art image classification pipelines.\n",
    "\n",
    "This guide will show you how to compose these layers into your own data\n",
    "augmentation pipeline for image classification tasks. This guide will also walk you\n",
    "through the process of customizing a KerasCV data augmentation pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Imports & setup\n",
    "\n",
    "This tutorial requires you to have KerasCV installed:\n",
    "\n",
    "```shell\n",
    "pip install keras-cv\n",
    "```\n",
    "\n",
    "We begin by importing all required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import keras_cv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Data loading\n",
    "\n",
    "This guide uses the\n",
    "[102 Category Flower Dataset](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/)\n",
    "for demonstration purposes.\n",
    "\n",
    "To get started, we first load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "tfds.disable_progress_bar()\n",
    "data, dataset_info = tfds.load(\"oxford_flowers102\", with_info=True, as_supervised=True)\n",
    "train_steps_per_epoch = dataset_info.splits[\"train\"].num_examples // BATCH_SIZE\n",
    "val_steps_per_epoch = dataset_info.splits[\"test\"].num_examples // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Next, we resize the images to a constant size, `(224, 224)`, and one-hot encode the\n",
    "labels. Please note that `keras_cv.layers.CutMix` and `keras_cv.layers.MixUp` expect\n",
    "targets to be one-hot encoded. This is because they modify the values of the targets\n",
    "in a way that is not possible with a sparse label representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224)\n",
    "num_classes = dataset_info.features[\"label\"].num_classes\n",
    "\n",
    "\n",
    "def to_dict(image, label):\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    return {\"images\": image, \"labels\": label}\n",
    "\n",
    "\n",
    "def prepare_dataset(dataset, split):\n",
    "    if split == \"train\":\n",
    "        return (\n",
    "            dataset.shuffle(10 * BATCH_SIZE)\n",
    "            .map(to_dict, num_parallel_calls=AUTOTUNE)\n",
    "            .batch(BATCH_SIZE)\n",
    "        )\n",
    "    if split == \"test\":\n",
    "        return dataset.map(to_dict, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "def load_dataset(split=\"train\"):\n",
    "    dataset = data[split]\n",
    "    return prepare_dataset(dataset, split)\n",
    "\n",
    "\n",
    "train_dataset = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's inspect some samples from our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def visualize_dataset(dataset, title):\n",
    "    plt.figure(figsize=(6, 6)).suptitle(title, fontsize=18)\n",
    "    for i, samples in enumerate(iter(dataset.take(9))):\n",
    "        images = samples[\"images\"]\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_dataset(train_dataset, title=\"Before Augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Great! Now we can move onto the augmentation step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## RandAugment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "[RandAugment](https://arxiv.org/abs/1909.13719)\n",
    "has been shown to provide improved image\n",
    "classification results across numerous datasets.\n",
    "It performs a standard set of augmentations on an image.\n",
    "\n",
    "To use RandAugment in KerasCV, you need to provide a few values:\n",
    "\n",
    "- `value_range` describes the range of values covered in your images\n",
    "- `magnitude` is a value between 0 and 1, describing the strength of the perturbations\n",
    "applied\n",
    "- `augmentations_per_image` is an integer telling the layer how many augmentations to apply to each\n",
    "individual image\n",
    "- (Optional) `magnitude_stddev` allows `magnitude` to be randomly sampled\n",
    "from a distribution with a standard deviation of `magnitude_stddev`\n",
    "- (Optional) `rate` indicates the probability to apply the augmentation\n",
    "applied at each layer.\n",
    "\n",
    "You can read more about these\n",
    "parameters in the\n",
    "[`RandAugment` API documentation](/api/keras_cv/layers/preprocessing/rand_augment/).\n",
    "\n",
    "Let's use KerasCV's RandAugment implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "rand_augment = keras_cv.layers.RandAugment(\n",
    "    value_range=(0, 255),\n",
    "    augmentations_per_image=3,\n",
    "    magnitude=0.3,\n",
    "    magnitude_stddev=0.2,\n",
    "    rate=0.5,\n",
    ")\n",
    "\n",
    "\n",
    "def apply_rand_augment(inputs):\n",
    "    inputs[\"images\"] = rand_augment(inputs[\"images\"])\n",
    "    return inputs\n",
    "\n",
    "\n",
    "train_dataset = load_dataset().map(apply_rand_augment, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Finally, let's inspect some of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "visualize_dataset(train_dataset, title=\"After RandAugment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Try tweaking the magnitude settings to see a wider variety of results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## CutMix and MixUp: generate high-quality inter-class examples\n",
    "\n",
    "\n",
    "`CutMix` and `MixUp` allow us to produce inter-class examples. `CutMix` randomly cuts out\n",
    "portions of one image and places them over another, and `MixUp` interpolates the pixel\n",
    "values between two images. Both of these prevent the model from overfitting the\n",
    "training distribution and improve the likelihood that the model can generalize to out of\n",
    "distribution examples. Additionally, `CutMix` prevents your model from over-relying on\n",
    "any particular feature to perform its classifications. You can read more about these\n",
    "techniques in their respective papers:\n",
    "\n",
    "- [CutMix: Train Strong Classifiers](https://arxiv.org/abs/1905.04899)\n",
    "- [MixUp: Beyond Empirical Risk Minimization](https://arxiv.org/abs/1710.09412)\n",
    "\n",
    "In this example, we will use `CutMix` and `MixUp` independently in a manually created\n",
    "preprocessing pipeline. In most state of the art pipelines images are randomly\n",
    "augmented by either `CutMix`, `MixUp`, or neither. The function below implements both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "cut_mix = keras_cv.layers.CutMix()\n",
    "mix_up = keras_cv.layers.MixUp()\n",
    "\n",
    "\n",
    "def cut_mix_and_mix_up(samples):\n",
    "    samples = cut_mix(samples, training=True)\n",
    "    samples = mix_up(samples, training=True)\n",
    "    return samples\n",
    "\n",
    "\n",
    "train_dataset = load_dataset().map(cut_mix_and_mix_up, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "visualize_dataset(train_dataset, title=\"After CutMix and MixUp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Great! Looks like we have successfully added `CutMix` and `MixUp` to our preprocessing\n",
    "pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Customizing your augmentation pipeline\n",
    "\n",
    "Perhaps you want to exclude an augmentation from `RandAugment`, or perhaps you want to\n",
    "include the `keras_cv.layers.GridMask` as an option alongside the default `RandAugment`\n",
    "augmentations.\n",
    "\n",
    "KerasCV allows you to construct production grade custom data augmentation pipelines using\n",
    "the `keras_cv.layers.RandomAugmentationPipeline` layer. This class operates similarly to\n",
    "`RandAugment`; selecting a random layer to apply to each image `augmentations_per_image`\n",
    "times. `RandAugment` can be thought of as a specific case of\n",
    "`RandomAugmentationPipeline`. In fact, our `RandAugment` implementation inherits from\n",
    "`RandomAugmentationPipeline` internally.\n",
    "\n",
    "In this example, we will create a custom `RandomAugmentationPipeline` by removing\n",
    "`RandomRotation` layers from the standard `RandAugment` policy, and substitutex a\n",
    "`GridMask` layer in its place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "As a first step, let's use the helper method `RandAugment.get_standard_policy()` to\n",
    "create a base pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "layers = keras_cv.layers.RandAugment.get_standard_policy(\n",
    "    value_range=(0, 255), magnitude=0.75, magnitude_stddev=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "First, let's filter out `RandomRotation` layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "layers = [\n",
    "    layer for layer in layers if not isinstance(layer, keras_cv.layers.RandomRotation)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Next, let's add `keras_cv.layers.GridMask` to our layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "layers = layers + [keras_cv.layers.GridMask()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Finally, we can put together our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "pipeline = keras_cv.layers.RandomAugmentationPipeline(\n",
    "    layers=layers, augmentations_per_image=3\n",
    ")\n",
    "\n",
    "\n",
    "def apply_pipeline(inputs):\n",
    "    inputs[\"images\"] = pipeline(inputs[\"images\"])\n",
    "    return inputs\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's check out the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_dataset = load_dataset().map(apply_pipeline, num_parallel_calls=AUTOTUNE)\n",
    "visualize_dataset(train_dataset, title=\"After custom pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Awesome! As you can see, no images were randomly rotated. You can customize the\n",
    "pipeline however you like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "pipeline = keras_cv.layers.RandomAugmentationPipeline(\n",
    "    layers=[keras_cv.layers.GridMask(), keras_cv.layers.Grayscale(output_channels=3)],\n",
    "    augmentations_per_image=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This pipeline will either apply `GrayScale` or GridMask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = load_dataset().map(apply_pipeline, num_parallel_calls=AUTOTUNE)\n",
    "visualize_dataset(train_dataset, title=\"After custom pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Looks great! You can use `RandomAugmentationPipeline` however you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Training a CNN\n",
    "\n",
    "As a final exercise, let's take some of these layers for a spin. In this section, we\n",
    "will use `CutMix`, `MixUp`, and `RandAugment` to train a state of the art `ResNet50`\n",
    "image classifier on the Oxford flowers dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_for_model(inputs):\n",
    "    images, labels = inputs[\"images\"], inputs[\"labels\"]\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "train_dataset = (\n",
    "    load_dataset()\n",
    "    .map(apply_rand_augment, num_parallel_calls=AUTOTUNE)\n",
    "    .map(cut_mix_and_mix_up, num_parallel_calls=AUTOTUNE)\n",
    ")\n",
    "\n",
    "visualize_dataset(train_dataset, \"CutMix, MixUp and RandAugment\")\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_for_model, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "test_dataset = load_dataset(split=\"test\")\n",
    "test_dataset = test_dataset.map(preprocess_for_model, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "train_dataset = train_dataset.prefetch(AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(AUTOTUNE)\n",
    "\n",
    "train_dataset = train_dataset\n",
    "test_dataset = test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Next we should create a the model itself. Notice that we use `label_smoothing=0.1` in\n",
    "the loss function. When using `MixUp`, label smoothing is _highly_ recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "input_shape = IMAGE_SIZE + (3,)\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = keras_cv.models.DenseNet121(\n",
    "        include_rescaling=True, include_top=True, classes=num_classes\n",
    "    )\n",
    "    model.compile(\n",
    "        loss=losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "        optimizer=optimizers.SGD(momentum=0.9),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Finally we train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    model = get_model()\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=1,\n",
    "        validation_data=test_dataset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Conclusion & next steps\n",
    "\n",
    "That's all it takes to assemble state of the art image augmentation pipeliens with\n",
    "KerasCV!\n",
    "\n",
    "As an additional exercise for readers, you can:\n",
    "\n",
    "- Perform a hyper parameter search over the RandAugment parameters to improve the\n",
    "classifier accuracy\n",
    "- Substitute the Oxford Flowers dataset with your own dataset\n",
    "- Experiment with custom `RandomAugmentationPipeline` objects.\n",
    "\n",
    "Currently, between Keras core and KerasCV there are\n",
    "[_28 image augmentation layers_](https://keras.io/api/keras_cv/layers/preprocessing)!\n",
    "Each of these can be used independently, or in a pipeline. Check them out, and if you\n",
    "find an augmentation techniques you need is missing please file a\n",
    "[GitHub issue on KerasCV](https://github.com/keras-team/keras-cv/issues)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cut_mix_mix_up_and_rand_augment",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}