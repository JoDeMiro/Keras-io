{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Metric learning for image similarity search\n",
    "\n",
    "**Author:** [Mat Kelcey](https://twitter.com/mat_kelcey)<br>\n",
    "**Date created:** 2020/06/05<br>\n",
    "**Last modified:** 2020/06/09<br>\n",
    "**Description:** Example of using similarity metric learning on CIFAR-10 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Metric learning aims to train models that can embed inputs into a high-dimensional space\n",
    "such that \"similar\" inputs, as defined by the training scheme, are located close to each\n",
    "other. These models once trained can produce embeddings for downstream systems where such\n",
    "similarity is useful; examples include as a ranking signal for search or as a form of\n",
    "pretrained embedding model for another supervised problem.\n",
    "\n",
    "For a more detailed overview of metric learning see:\n",
    "\n",
    "* [What is metric learning?](http://contrib.scikit-learn.org/metric-learn/introduction.html)\n",
    "* [\"Using crossentropy for metric learning\" tutorial](https://www.youtube.com/watch?v=Jb4Ewl5RzkI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "For this example we will be using the\n",
    "[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "y_train = np.squeeze(y_train)\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "y_test = np.squeeze(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "To get a sense of the dataset we can visualise a grid of 25 random examples.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "height_width = 32\n",
    "\n",
    "\n",
    "def show_collage(examples):\n",
    "    box_size = height_width + 2\n",
    "    num_rows, num_cols = examples.shape[:2]\n",
    "\n",
    "    collage = Image.new(\n",
    "        mode=\"RGB\",\n",
    "        size=(num_cols * box_size, num_rows * box_size),\n",
    "        color=(250, 250, 250),\n",
    "    )\n",
    "    for row_idx in range(num_rows):\n",
    "        for col_idx in range(num_cols):\n",
    "            array = (np.array(examples[row_idx, col_idx]) * 255).astype(np.uint8)\n",
    "            collage.paste(\n",
    "                Image.fromarray(array), (col_idx * box_size, row_idx * box_size)\n",
    "            )\n",
    "\n",
    "    # Double size for visualisation.\n",
    "    collage = collage.resize((2 * num_cols * box_size, 2 * num_rows * box_size))\n",
    "    return collage\n",
    "\n",
    "\n",
    "# Show a collage of 5x5 random images.\n",
    "sample_idxs = np.random.randint(0, 50000, size=(5, 5))\n",
    "examples = x_train[sample_idxs]\n",
    "show_collage(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Metric learning provides training data not as explicit `(X, y)` pairs but instead uses\n",
    "multiple instances that are related in the way we want to express similarity. In our\n",
    "example we will use instances of the same class to represent similarity; a single\n",
    "training instance will not be one image, but a pair of images of the same class. When\n",
    "referring to the images in this pair we'll use the common metric learning names of the\n",
    "`anchor` (a randomly chosen image) and the `positive` (another randomly chosen image of\n",
    "the same class).\n",
    "\n",
    "To facilitate this we need to build a form of lookup that maps from classes to the\n",
    "instances of that class. When generating data for training we will sample from this\n",
    "lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class_idx_to_train_idxs = defaultdict(list)\n",
    "for y_train_idx, y in enumerate(y_train):\n",
    "    class_idx_to_train_idxs[y].append(y_train_idx)\n",
    "\n",
    "class_idx_to_test_idxs = defaultdict(list)\n",
    "for y_test_idx, y in enumerate(y_test):\n",
    "    class_idx_to_test_idxs[y].append(y_test_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "For this example we are using the simplest approach to training; a batch will consist of\n",
    "`(anchor, positive)` pairs spread across the classes. The goal of learning will be to\n",
    "move the anchor and positive pairs closer together and further away from other instances\n",
    "in the batch. In this case the batch size will be dictated by the number of classes; for\n",
    "CIFAR-10 this is 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "\n",
    "class AnchorPositivePairs(keras.utils.Sequence):\n",
    "    def __init__(self, num_batchs):\n",
    "        self.num_batchs = num_batchs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batchs\n",
    "\n",
    "    def __getitem__(self, _idx):\n",
    "        x = np.empty((2, num_classes, height_width, height_width, 3), dtype=np.float32)\n",
    "        for class_idx in range(num_classes):\n",
    "            examples_for_class = class_idx_to_train_idxs[class_idx]\n",
    "            anchor_idx = random.choice(examples_for_class)\n",
    "            positive_idx = random.choice(examples_for_class)\n",
    "            while positive_idx == anchor_idx:\n",
    "                positive_idx = random.choice(examples_for_class)\n",
    "            x[0, class_idx] = x_train[anchor_idx]\n",
    "            x[1, class_idx] = x_train[positive_idx]\n",
    "        return x\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We can visualise a batch in another collage. The top row shows randomly chosen anchors\n",
    "from the 10 classes, the bottom row shows the corresponding 10 positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "examples = next(iter(AnchorPositivePairs(num_batchs=1)))\n",
    "\n",
    "show_collage(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Embedding model\n",
    "\n",
    "We define a custom model with a `train_step` that first embeds both anchors and positives\n",
    "and then uses their pairwise dot products as logits for a softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class EmbeddingModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        # Note: Workaround for open issue, to be removed.\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        anchors, positives = data[0], data[1]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Run both anchors and positives through model.\n",
    "            anchor_embeddings = self(anchors, training=True)\n",
    "            positive_embeddings = self(positives, training=True)\n",
    "\n",
    "            # Calculate cosine similarity between anchors and positives. As they have\n",
    "            # been normalised this is just the pair wise dot products.\n",
    "            similarities = tf.einsum(\n",
    "                \"ae,pe->ap\", anchor_embeddings, positive_embeddings\n",
    "            )\n",
    "\n",
    "            # Since we intend to use these as logits we scale them by a temperature.\n",
    "            # This value would normally be chosen as a hyper parameter.\n",
    "            temperature = 0.2\n",
    "            similarities /= temperature\n",
    "\n",
    "            # We use these similarities as logits for a softmax. The labels for\n",
    "            # this call are just the sequence [0, 1, 2, ..., num_classes] since we\n",
    "            # want the main diagonal values, which correspond to the anchor/positive\n",
    "            # pairs, to be high. This loss will move embeddings for the\n",
    "            # anchor/positive pairs together and move all other pairs apart.\n",
    "            sparse_labels = tf.range(num_classes)\n",
    "            loss = self.compiled_loss(sparse_labels, similarities)\n",
    "\n",
    "        # Calculate gradients and apply via optimizer.\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        # Update and return metrics (specifically the one for the loss value).\n",
    "        self.compiled_metrics.update_state(sparse_labels, similarities)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Next we describe the architecture that maps from an image to an embedding. This model\n",
    "simply consists of a sequence of 2d convolutions followed by global pooling with a final\n",
    "linear projection to an embedding space. As is common in metric learning we normalise the\n",
    "embeddings so that we can use simple dot products to measure similarity. For simplicity\n",
    "this model is intentionally small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(height_width, height_width, 3))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, strides=2, activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, strides=2, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, strides=2, activation=\"relu\")(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "embeddings = layers.Dense(units=8, activation=None)(x)\n",
    "embeddings = tf.nn.l2_normalize(embeddings, axis=-1)\n",
    "\n",
    "model = EmbeddingModel(inputs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Finally we run the training. On a Google Colab GPU instance this takes about a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "history = model.fit(AnchorPositivePairs(num_batchs=1000), epochs=20)\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Testing\n",
    "\n",
    "We can review the quality of this model by applying it to the test set and considering\n",
    "near neighbours in the embedding space.\n",
    "\n",
    "First we embed the test set and calculate all near neighbours. Recall that since the\n",
    "embeddings are unit length we can calculate cosine similarity via dot products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "near_neighbours_per_example = 10\n",
    "\n",
    "embeddings = model.predict(x_test)\n",
    "gram_matrix = np.einsum(\"ae,be->ab\", embeddings, embeddings)\n",
    "near_neighbours = np.argsort(gram_matrix.T)[:, -(near_neighbours_per_example + 1) :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "As a visual check of these embeddings we can build a collage of the near neighbours for 5\n",
    "random examples. The first column of the image below is a randomly selected image, the\n",
    "following 10 columns show the nearest neighbours in order of similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "num_collage_examples = 5\n",
    "\n",
    "examples = np.empty(\n",
    "    (\n",
    "        num_collage_examples,\n",
    "        near_neighbours_per_example + 1,\n",
    "        height_width,\n",
    "        height_width,\n",
    "        3,\n",
    "    ),\n",
    "    dtype=np.float32,\n",
    ")\n",
    "for row_idx in range(num_collage_examples):\n",
    "    examples[row_idx, 0] = x_test[row_idx]\n",
    "    anchor_near_neighbours = reversed(near_neighbours[row_idx][:-1])\n",
    "    for col_idx, nn_idx in enumerate(anchor_near_neighbours):\n",
    "        examples[row_idx, col_idx + 1] = x_test[nn_idx]\n",
    "\n",
    "show_collage(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We can also get a quantified view of the performance by considering the correctness of\n",
    "near neighbours in terms of a confusion matrix.\n",
    "\n",
    "Let us sample 10 examples from each of the 10 classes and consider their near neighbours\n",
    "as a form of prediction; that is, does the example and its near neighbours share the same\n",
    "class?\n",
    "\n",
    "We observe that each animal class does generally well, and is confused the most with the\n",
    "other animal classes. The vehicle classes follow the same pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "confusion_matrix = np.zeros((num_classes, num_classes))\n",
    "\n",
    "# For each class.\n",
    "for class_idx in range(num_classes):\n",
    "    # Consider 10 examples.\n",
    "    example_idxs = class_idx_to_test_idxs[class_idx][:10]\n",
    "    for y_test_idx in example_idxs:\n",
    "        # And count the classes of its near neighbours.\n",
    "        for nn_idx in near_neighbours[y_test_idx][:-1]:\n",
    "            nn_class_idx = y_test[nn_idx]\n",
    "            confusion_matrix[class_idx, nn_class_idx] += 1\n",
    "\n",
    "# Display a confusion matrix.\n",
    "labels = [\n",
    "    \"Airplane\",\n",
    "    \"Automobile\",\n",
    "    \"Bird\",\n",
    "    \"Cat\",\n",
    "    \"Deer\",\n",
    "    \"Dog\",\n",
    "    \"Frog\",\n",
    "    \"Horse\",\n",
    "    \"Ship\",\n",
    "    \"Truck\",\n",
    "]\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=labels)\n",
    "disp.plot(include_values=True, cmap=\"viridis\", ax=None, xticks_rotation=\"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Example available on HuggingFace.\n",
    "\n",
    "| Trained Model | Demo |\n",
    "| :--: | :--: |\n",
    "| [![Generic badge](https://img.shields.io/badge/\ud83e\udd17%20Model-Cifar10%20Metric%20Learning-black.svg)](https://huggingface.co/keras-io/cifar10_metric_learning) | [![Generic badge](https://img.shields.io/badge/\ud83e\udd17%20Spaces-Metric%20Learning%20for%20Image%20Similarity%20Search-black.svg)](https://huggingface.co/spaces/keras-io/metric-learning-image-similarity-search) |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "metric_learning",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}