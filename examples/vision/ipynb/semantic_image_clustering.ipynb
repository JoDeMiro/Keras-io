{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Semantic Image Clustering\n",
    "\n",
    "**Author:** [Khalid Salama](https://www.linkedin.com/in/khalid-salama-24403144/)<br>\n",
    "**Date created:** 2021/02/28<br>\n",
    "**Last modified:** 2021/02/28<br>\n",
    "**Description:** Semantic Clustering by Adopting Nearest neighbors (SCAN) algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This example demonstrates how to apply the [Semantic Clustering by Adopting Nearest neighbors\n",
    "(SCAN)](https://arxiv.org/abs/2005.12320) algorithm (Van Gansbeke et al., 2020) on the\n",
    "[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset. The algorithm consists of\n",
    "two phases:\n",
    "\n",
    "1. Self-supervised visual representation learning of images, in which we use the\n",
    "[simCLR](https://arxiv.org/abs/2002.05709) technique.\n",
    "2. Clustering of the learned visual representation vectors to maximize the agreement\n",
    "between the cluster assignments of neighboring vectors.\n",
    "\n",
    "The example requires [TensorFlow Addons](https://www.tensorflow.org/addons),\n",
    "which you can install using the following command:\n",
    "\n",
    "```python\n",
    "pip install tensorflow-addons\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_data = np.concatenate([x_train, x_test])\n",
    "y_data = np.concatenate([y_train, y_test])\n",
    "\n",
    "print(\"x_data shape:\", x_data.shape, \"- y_data shape:\", y_data.shape)\n",
    "\n",
    "classes = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "target_size = 32  # Resize the input images.\n",
    "representation_dim = 512  # The dimensions of the features vector.\n",
    "projection_units = 128  # The projection head of the representation learner.\n",
    "num_clusters = 20  # Number of clusters.\n",
    "k_neighbours = 5  # Number of neighbours to consider during cluster learning.\n",
    "tune_encoder_during_clustering = False  # Freeze the encoder in the cluster learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Implement data preprocessing\n",
    "\n",
    "The data preprocessing step resizes the input images to the desired `target_size` and applies\n",
    "feature-wise normalization. Note that, when using `keras.applications.ResNet50V2` as the\n",
    "visual encoder, resizing the images into 255 x 255 inputs would lead to more accurate results\n",
    "but require a longer time to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data_preprocessing = keras.Sequential(\n",
    "    [\n",
    "        layers.Resizing(target_size, target_size),\n",
    "        layers.Normalization(),\n",
    "    ]\n",
    ")\n",
    "# Compute the mean and the variance from the data for normalization.\n",
    "data_preprocessing.layers[-1].adapt(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Data augmentation\n",
    "\n",
    "Unlike simCLR, which randomly picks a single data augmentation function to apply to an input\n",
    "image, we apply a set of data augmentation functions randomly to the input image.\n",
    "(You can experiment with other image augmentation techniques by following the [data augmentation tutorial](https://www.tensorflow.org/tutorials/images/data_augmentation).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomTranslation(\n",
    "            height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2), fill_mode=\"nearest\"\n",
    "        ),\n",
    "        layers.RandomFlip(mode=\"horizontal\"),\n",
    "        layers.RandomRotation(\n",
    "            factor=0.15, fill_mode=\"nearest\"\n",
    "        ),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=(-0.3, 0.1), width_factor=(-0.3, 0.1), fill_mode=\"nearest\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Display a random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "image_idx = np.random.choice(range(x_data.shape[0]))\n",
    "image = x_data[image_idx]\n",
    "image_class = classes[y_data[image_idx][0]]\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(x_data[image_idx].astype(\"uint8\"))\n",
    "plt.title(image_class)\n",
    "_ = plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Display a sample of augmented versions of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    augmented_images = data_augmentation(np.array([image]))\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Self-supervised representation learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Implement the vision encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_encoder(representation_dim):\n",
    "    encoder = keras.Sequential(\n",
    "        [\n",
    "            keras.applications.ResNet50V2(\n",
    "                include_top=False, weights=None, pooling=\"avg\"\n",
    "            ),\n",
    "            layers.Dense(representation_dim),\n",
    "        ]\n",
    "    )\n",
    "    return encoder\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Implement the unsupervised contrastive loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class RepresentationLearner(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder,\n",
    "        projection_units,\n",
    "        num_augmentations,\n",
    "        temperature=1.0,\n",
    "        dropout_rate=0.1,\n",
    "        l2_normalize=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(RepresentationLearner, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        # Create projection head.\n",
    "        self.projector = keras.Sequential(\n",
    "            [\n",
    "                layers.Dropout(dropout_rate),\n",
    "                layers.Dense(units=projection_units, use_bias=False),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.ReLU(),\n",
    "            ]\n",
    "        )\n",
    "        self.num_augmentations = num_augmentations\n",
    "        self.temperature = temperature\n",
    "        self.l2_normalize = l2_normalize\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker]\n",
    "\n",
    "    def compute_contrastive_loss(self, feature_vectors, batch_size):\n",
    "        num_augmentations = tf.shape(feature_vectors)[0] // batch_size\n",
    "        if self.l2_normalize:\n",
    "            feature_vectors = tf.math.l2_normalize(feature_vectors, -1)\n",
    "        # The logits shape is [num_augmentations * batch_size, num_augmentations * batch_size].\n",
    "        logits = (\n",
    "            tf.linalg.matmul(feature_vectors, feature_vectors, transpose_b=True)\n",
    "            / self.temperature\n",
    "        )\n",
    "        # Apply log-max trick for numerical stability.\n",
    "        logits_max = tf.math.reduce_max(logits, axis=1)\n",
    "        logits = logits - logits_max\n",
    "        # The shape of targets is [num_augmentations * batch_size, num_augmentations * batch_size].\n",
    "        # targets is a matrix consits of num_augmentations submatrices of shape [batch_size * batch_size].\n",
    "        # Each [batch_size * batch_size] submatrix is an identity matrix (diagonal entries are ones).\n",
    "        targets = tf.tile(tf.eye(batch_size), [num_augmentations, num_augmentations])\n",
    "        # Compute cross entropy loss\n",
    "        return keras.losses.categorical_crossentropy(\n",
    "            y_true=targets, y_pred=logits, from_logits=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Preprocess the input images.\n",
    "        preprocessed = data_preprocessing(inputs)\n",
    "        # Create augmented versions of the images.\n",
    "        augmented = []\n",
    "        for _ in range(self.num_augmentations):\n",
    "            augmented.append(data_augmentation(preprocessed))\n",
    "        augmented = layers.Concatenate(axis=0)(augmented)\n",
    "        # Generate embedding representations of the images.\n",
    "        features = self.encoder(augmented)\n",
    "        # Apply projection head.\n",
    "        return self.projector(features)\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        # Run the forward pass and compute the contrastive loss\n",
    "        with tf.GradientTape() as tape:\n",
    "            feature_vectors = self(inputs, training=True)\n",
    "            loss = self.compute_contrastive_loss(feature_vectors, batch_size)\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update loss tracker metric\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        feature_vectors = self(inputs, training=False)\n",
    "        loss = self.compute_contrastive_loss(feature_vectors, batch_size)\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Create vision encoder.\n",
    "encoder = create_encoder(representation_dim)\n",
    "# Create representation learner.\n",
    "representation_learner = RepresentationLearner(\n",
    "    encoder, projection_units, num_augmentations=2, temperature=0.1\n",
    ")\n",
    "# Create a a Cosine decay learning rate scheduler.\n",
    "lr_scheduler = keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=0.001, decay_steps=500, alpha=0.1\n",
    ")\n",
    "# Compile the model.\n",
    "representation_learner.compile(\n",
    "    optimizer=tfa.optimizers.AdamW(learning_rate=lr_scheduler, weight_decay=0.0001),\n",
    ")\n",
    "# Fit the model.\n",
    "history = representation_learner.fit(\n",
    "    x=x_data,\n",
    "    batch_size=512,\n",
    "    epochs=50,  # for better results, increase the number of epochs to 500.\n",
    ")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Plot training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Compute the nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Generate the embeddings for the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "# Get the feature vector representations of the images.\n",
    "feature_vectors = encoder.predict(x_data, batch_size=batch_size, verbose=1)\n",
    "# Normalize the feature vectores.\n",
    "feature_vectors = tf.math.l2_normalize(feature_vectors, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Find the *k* nearest neighbours for each embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "neighbours = []\n",
    "num_batches = feature_vectors.shape[0] // batch_size\n",
    "for batch_idx in tqdm(range(num_batches)):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = start_idx + batch_size\n",
    "    current_batch = feature_vectors[start_idx:end_idx]\n",
    "    # Compute the dot similarity.\n",
    "    similarities = tf.linalg.matmul(current_batch, feature_vectors, transpose_b=True)\n",
    "    # Get the indices of most similar vectors.\n",
    "    _, indices = tf.math.top_k(similarities, k=k_neighbours + 1, sorted=True)\n",
    "    # Add the indices to the neighbours.\n",
    "    neighbours.append(indices[..., 1:])\n",
    "\n",
    "neighbours = np.reshape(np.array(neighbours), (-1, k_neighbours))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's display some neighbors on each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "nrows = 4\n",
    "ncols = k_neighbours + 1\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "position = 1\n",
    "for _ in range(nrows):\n",
    "    anchor_idx = np.random.choice(range(x_data.shape[0]))\n",
    "    neighbour_indicies = neighbours[anchor_idx]\n",
    "    indices = [anchor_idx] + neighbour_indicies.tolist()\n",
    "    for j in range(ncols):\n",
    "        plt.subplot(nrows, ncols, position)\n",
    "        plt.imshow(x_data[indices[j]].astype(\"uint8\"))\n",
    "        plt.title(classes[y_data[indices[j]][0]])\n",
    "        plt.axis(\"off\")\n",
    "        position += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "You notice that images on each row are visually similar, and belong to similar classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Semantic clustering with nearest neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Implement clustering consistency loss\n",
    "\n",
    "This loss tries to make sure that neighbours have the same clustering assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ClustersConsistencyLoss(keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super(ClustersConsistencyLoss, self).__init__()\n",
    "\n",
    "    def __call__(self, target, similarity, sample_weight=None):\n",
    "        # Set targets to be ones.\n",
    "        target = tf.ones_like(similarity)\n",
    "        # Compute cross entropy loss.\n",
    "        loss = keras.losses.binary_crossentropy(\n",
    "            y_true=target, y_pred=similarity, from_logits=True\n",
    "        )\n",
    "        return tf.math.reduce_mean(loss)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Implement the clusters entropy loss\n",
    "\n",
    "This loss tries to make sure that cluster distribution is roughly uniformed, to avoid\n",
    "assigning most of the instances to one cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ClustersEntropyLoss(keras.losses.Loss):\n",
    "    def __init__(self, entropy_loss_weight=1.0):\n",
    "        super(ClustersEntropyLoss, self).__init__()\n",
    "        self.entropy_loss_weight = entropy_loss_weight\n",
    "\n",
    "    def __call__(self, target, cluster_probabilities, sample_weight=None):\n",
    "        # Ideal entropy = log(num_clusters).\n",
    "        num_clusters = tf.cast(tf.shape(cluster_probabilities)[-1], tf.dtypes.float32)\n",
    "        target = tf.math.log(num_clusters)\n",
    "        # Compute the overall clusters distribution.\n",
    "        cluster_probabilities = tf.math.reduce_mean(cluster_probabilities, axis=0)\n",
    "        # Replacing zero probabilities - if any - with a very small value.\n",
    "        cluster_probabilities = tf.clip_by_value(\n",
    "            cluster_probabilities, clip_value_min=1e-8, clip_value_max=1.0\n",
    "        )\n",
    "        # Compute the entropy over the clusters.\n",
    "        entropy = -tf.math.reduce_sum(\n",
    "            cluster_probabilities * tf.math.log(cluster_probabilities)\n",
    "        )\n",
    "        # Compute the difference between the target and the actual.\n",
    "        loss = target - entropy\n",
    "        return loss\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Implement clustering model\n",
    "\n",
    "This model takes a raw image as an input, generated its feature vector using the trained\n",
    "encoder, and produces a probability distribution of the clusters given the feature vector\n",
    "as the cluster assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_clustering_model(encoder, num_clusters, name=None):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Preprocess the input images.\n",
    "    preprocessed = data_preprocessing(inputs)\n",
    "    # Apply data augmentation to the images.\n",
    "    augmented = data_augmentation(preprocessed)\n",
    "    # Generate embedding representations of the images.\n",
    "    features = encoder(augmented)\n",
    "    # Assign the images to clusters.\n",
    "    outputs = layers.Dense(units=num_clusters, activation=\"softmax\")(features)\n",
    "    # Create the model.\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
    "    return model\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Implement clustering learner\n",
    "\n",
    "This model receives the input `anchor` image and its `neighbours`, produces the clusters\n",
    "assignments for them using the `clustering_model`, and produces two outputs:\n",
    "1. `similarity`: the similarity between the cluster assignments of the `anchor` image and\n",
    "its `neighbours`. This output is fed to the `ClustersConsistencyLoss`.\n",
    "2. `anchor_clustering`: cluster assignments of the `anchor` images. This is fed to the `ClustersEntropyLoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_clustering_learner(clustering_model):\n",
    "    anchor = keras.Input(shape=input_shape, name=\"anchors\")\n",
    "    neighbours = keras.Input(\n",
    "        shape=tuple([k_neighbours]) + input_shape, name=\"neighbours\"\n",
    "    )\n",
    "    # Changes neighbours shape to [batch_size * k_neighbours, width, height, channels]\n",
    "    neighbours_reshaped = tf.reshape(neighbours, shape=tuple([-1]) + input_shape)\n",
    "    # anchor_clustering shape: [batch_size, num_clusters]\n",
    "    anchor_clustering = clustering_model(anchor)\n",
    "    # neighbours_clustering shape: [batch_size * k_neighbours, num_clusters]\n",
    "    neighbours_clustering = clustering_model(neighbours_reshaped)\n",
    "    # Convert neighbours_clustering shape to [batch_size, k_neighbours, num_clusters]\n",
    "    neighbours_clustering = tf.reshape(\n",
    "        neighbours_clustering,\n",
    "        shape=(-1, k_neighbours, tf.shape(neighbours_clustering)[-1]),\n",
    "    )\n",
    "    # similarity shape: [batch_size, 1, k_neighbours]\n",
    "    similarity = tf.linalg.einsum(\n",
    "        \"bij,bkj->bik\", tf.expand_dims(anchor_clustering, axis=1), neighbours_clustering\n",
    "    )\n",
    "    # similarity shape:  [batch_size, k_neighbours]\n",
    "    similarity = layers.Lambda(lambda x: tf.squeeze(x, axis=1), name=\"similarity\")(\n",
    "        similarity\n",
    "    )\n",
    "    # Create the model.\n",
    "    model = keras.Model(\n",
    "        inputs=[anchor, neighbours],\n",
    "        outputs=[similarity, anchor_clustering],\n",
    "        name=\"clustering_learner\",\n",
    "    )\n",
    "    return model\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# If tune_encoder_during_clustering is set to False,\n",
    "# then freeze the encoder weights.\n",
    "for layer in encoder.layers:\n",
    "    layer.trainable = tune_encoder_during_clustering\n",
    "# Create the clustering model and learner.\n",
    "clustering_model = create_clustering_model(encoder, num_clusters, name=\"clustering\")\n",
    "clustering_learner = create_clustering_learner(clustering_model)\n",
    "# Instantiate the model losses.\n",
    "losses = [ClustersConsistencyLoss(), ClustersEntropyLoss(entropy_loss_weight=5)]\n",
    "# Create the model inputs and labels.\n",
    "inputs = {\"anchors\": x_data, \"neighbours\": tf.gather(x_data, neighbours)}\n",
    "labels = tf.ones(shape=(x_data.shape[0]))\n",
    "# Compile the model.\n",
    "clustering_learner.compile(\n",
    "    optimizer=tfa.optimizers.AdamW(learning_rate=0.0005, weight_decay=0.0001),\n",
    "    loss=losses,\n",
    ")\n",
    "\n",
    "# Begin training the model.\n",
    "clustering_learner.fit(x=inputs, y=labels, batch_size=512, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Plot training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Cluster analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Assign images to clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Get the cluster probability distribution of the input images.\n",
    "clustering_probs = clustering_model.predict(x_data, batch_size=batch_size, verbose=1)\n",
    "# Get the cluster of the highest probability.\n",
    "cluster_assignments = tf.math.argmax(clustering_probs, axis=-1).numpy()\n",
    "# Store the clustering confidence.\n",
    "# Images with the highest clustering confidence are considered the 'prototypes'\n",
    "# of the clusters.\n",
    "cluster_confidence = tf.math.reduce_max(clustering_probs, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's compute the cluster sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "clusters = defaultdict(list)\n",
    "for idx, c in enumerate(cluster_assignments):\n",
    "    clusters[c].append((idx, cluster_confidence[idx]))\n",
    "\n",
    "for c in range(num_clusters):\n",
    "    print(\"cluster\", c, \":\", len(clusters[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Notice that the clusters have roughly balanced sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Visualize cluster images\n",
    "\n",
    "Display the *prototypes*\u2014instances with the highest clustering confidence\u2014of each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "num_images = 8\n",
    "plt.figure(figsize=(15, 15))\n",
    "position = 1\n",
    "for c in range(num_clusters):\n",
    "    cluster_instances = sorted(clusters[c], key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "    for j in range(num_images):\n",
    "        image_idx = cluster_instances[j][0]\n",
    "        plt.subplot(num_clusters, num_images, position)\n",
    "        plt.imshow(x_data[image_idx].astype(\"uint8\"))\n",
    "        plt.title(classes[y_data[image_idx][0]])\n",
    "        plt.axis(\"off\")\n",
    "        position += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Compute clustering accuracy\n",
    "\n",
    "First, we assign a label for each cluster based on the majority label of its images.\n",
    "Then, we compute the accuracy of each cluster by dividing the number of image with the\n",
    "majority label by the size of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "cluster_label_counts = dict()\n",
    "\n",
    "for c in range(num_clusters):\n",
    "    cluster_label_counts[c] = [0] * num_classes\n",
    "    instances = clusters[c]\n",
    "    for i, _ in instances:\n",
    "        cluster_label_counts[c][y_data[i][0]] += 1\n",
    "\n",
    "    cluster_label_idx = np.argmax(cluster_label_counts[c])\n",
    "    correct_count = np.max(cluster_label_counts[c])\n",
    "    cluster_size = len(clusters[c])\n",
    "    accuracy = (\n",
    "        np.round((correct_count / cluster_size) * 100, 2) if cluster_size > 0 else 0\n",
    "    )\n",
    "    cluster_label = classes[cluster_label_idx]\n",
    "    print(\"cluster\", c, \"label is:\", cluster_label, \" -  accuracy:\", accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "To improve the accuracy results, you can: 1) increase the number\n",
    "of epochs in the representation learning and the clustering phases; 2)\n",
    "allow the encoder weights to be tuned during the clustering phase; and 3) perform a final\n",
    "fine-tuning step through self-labeling, as described in the [original SCAN paper](https://arxiv.org/abs/2005.12320).\n",
    "Note that unsupervised image clustering techniques are not expected to outperform the accuracy\n",
    "of supervised image classification techniques, rather showing that they can learn the semantics\n",
    "of the images and group them into clusters that are similar to their original classes."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "semantic_image_clustering",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}