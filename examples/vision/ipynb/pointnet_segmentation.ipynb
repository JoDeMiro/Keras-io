{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Point cloud segmentation with PointNet\n",
    "\n",
    "**Author:** [Soumik Rakshit](https://github.com/soumik12345), [Sayak Paul](https://github.com/sayakpaul)<br>\n",
    "**Date created:** 2020/10/23<br>\n",
    "**Last modified:** 2020/10/24<br>\n",
    "**Description:** Implementation of a PointNet-based model for segmenting point clouds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "A \"point cloud\" is an important type of data structure for storing geometric shape data.\n",
    "Due to its irregular format, it's often transformed into\n",
    "regular 3D voxel grids or collections of images before being used in deep learning applications,\n",
    "a step which makes the data unnecessarily large.\n",
    "The PointNet family of models solves this problem by directly consuming point clouds, respecting\n",
    "the permutation-invariance property of the point data. The PointNet family of\n",
    "models provides a simple, unified architecture\n",
    "for applications ranging from **object classification**, **part segmentation**, to\n",
    "**scene semantic parsing**.\n",
    "\n",
    "In this example, we demonstrate the implementation of the PointNet architecture\n",
    "for shape segmentation.\n",
    "\n",
    "### References\n",
    "\n",
    "- [PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://arxiv.org/abs/1612.00593)\n",
    "- [Point cloud classification with PointNet](https://keras.io/examples/vision/pointnet/)\n",
    "- [Spatial Transformer Networks](https://arxiv.org/abs/1506.02025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Downloading Dataset\n",
    "\n",
    "The [ShapeNet dataset](https://shapenet.org/) is an ongoing effort to establish a richly-annotated,\n",
    "large-scale dataset of 3D shapes. **ShapeNetCore** is a subset of the full ShapeNet\n",
    "dataset with clean single 3D models and manually verified category and alignment\n",
    "annotations. It covers 55 common object categories, with about 51,300 unique 3D models.\n",
    "\n",
    "For this example, we use one of the 12 object categories of\n",
    "[PASCAL 3D+](http://cvgl.stanford.edu/projects/pascal3d.html),\n",
    "included as part of the ShapenetCore dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "dataset_url = \"https://git.io/JiY4i\"\n",
    "\n",
    "dataset_path = keras.utils.get_file(\n",
    "    fname=\"shapenet.zip\",\n",
    "    origin=dataset_url,\n",
    "    cache_subdir=\"datasets\",\n",
    "    hash_algorithm=\"auto\",\n",
    "    extract=True,\n",
    "    archive_format=\"auto\",\n",
    "    cache_dir=\"datasets\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Loading the dataset\n",
    "\n",
    "We parse the dataset metadata in order to easily map model categories to their\n",
    "respective directories and segmentation classes to colors for the purpose of\n",
    "visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "with open(\"/tmp/.keras/datasets/PartAnnotation/metadata.json\") as json_file:\n",
    "    metadata = json.load(json_file)\n",
    "\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "In this example, we train PointNet to segment the parts of an `Airplane` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "points_dir = \"/tmp/.keras/datasets/PartAnnotation/{}/points\".format(\n",
    "    metadata[\"Airplane\"][\"directory\"]\n",
    ")\n",
    "labels_dir = \"/tmp/.keras/datasets/PartAnnotation/{}/points_label\".format(\n",
    "    metadata[\"Airplane\"][\"directory\"]\n",
    ")\n",
    "LABELS = metadata[\"Airplane\"][\"lables\"]\n",
    "COLORS = metadata[\"Airplane\"][\"colors\"]\n",
    "\n",
    "VAL_SPLIT = 0.2\n",
    "NUM_SAMPLE_POINTS = 1024\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 60\n",
    "INITIAL_LR = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Structuring the dataset\n",
    "\n",
    "We generate the following in-memory data structures from the Airplane point clouds and\n",
    "their labels:\n",
    "\n",
    "- `point_clouds` is a list of `np.array` objects that represent the point cloud data in\n",
    "the form of x, y and z coordinates. Axis 0 represents the number of points in the\n",
    "point cloud, while axis 1 represents the coordinates. `all_labels` is the list\n",
    "that represents the label of each coordinate as a string (needed mainly for\n",
    "visualization purposes).\n",
    "- `test_point_clouds` is in the same format as `point_clouds`, but doesn't have\n",
    "corresponding the labels of the point clouds.\n",
    "- `all_labels` is a list of `np.array` objects that represent the point cloud labels\n",
    "for each coordinate, corresponding to the `point_clouds` list.\n",
    "- `point_cloud_labels` is a list of `np.array` objects that represent the point cloud\n",
    "labels for each coordinate in one-hot encoded form, corresponding to the `point_clouds`\n",
    "list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "point_clouds, test_point_clouds = [], []\n",
    "point_cloud_labels, all_labels = [], []\n",
    "\n",
    "points_files = glob(os.path.join(points_dir, \"*.pts\"))\n",
    "for point_file in tqdm(points_files):\n",
    "    point_cloud = np.loadtxt(point_file)\n",
    "    if point_cloud.shape[0] < NUM_SAMPLE_POINTS:\n",
    "        continue\n",
    "\n",
    "    # Get the file-id of the current point cloud for parsing its\n",
    "    # labels.\n",
    "    file_id = point_file.split(\"/\")[-1].split(\".\")[0]\n",
    "    label_data, num_labels = {}, 0\n",
    "    for label in LABELS:\n",
    "        label_file = os.path.join(labels_dir, label, file_id + \".seg\")\n",
    "        if os.path.exists(label_file):\n",
    "            label_data[label] = np.loadtxt(label_file).astype(\"float32\")\n",
    "            num_labels = len(label_data[label])\n",
    "\n",
    "    # Point clouds having labels will be our training samples.\n",
    "    try:\n",
    "        label_map = [\"none\"] * num_labels\n",
    "        for label in LABELS:\n",
    "            for i, data in enumerate(label_data[label]):\n",
    "                label_map[i] = label if data == 1 else label_map[i]\n",
    "        label_data = [\n",
    "            LABELS.index(label) if label != \"none\" else len(LABELS)\n",
    "            for label in label_map\n",
    "        ]\n",
    "        # Apply one-hot encoding to the dense label representation.\n",
    "        label_data = keras.utils.to_categorical(label_data, num_classes=len(LABELS) + 1)\n",
    "\n",
    "        point_clouds.append(point_cloud)\n",
    "        point_cloud_labels.append(label_data)\n",
    "        all_labels.append(label_map)\n",
    "    except KeyError:\n",
    "        test_point_clouds.append(point_cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Next, we take a look at some samples from the in-memory arrays we just generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    i = random.randint(0, len(point_clouds) - 1)\n",
    "    print(f\"point_clouds[{i}].shape:\", point_clouds[0].shape)\n",
    "    print(f\"point_cloud_labels[{i}].shape:\", point_cloud_labels[0].shape)\n",
    "    for j in range(5):\n",
    "        print(\n",
    "            f\"all_labels[{i}][{j}]:\",\n",
    "            all_labels[i][j],\n",
    "            f\"\\tpoint_cloud_labels[{i}][{j}]:\",\n",
    "            point_cloud_labels[i][j],\n",
    "            \"\\n\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Now, let's visualize some of the point clouds along with their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def visualize_data(point_cloud, labels):\n",
    "    df = pd.DataFrame(\n",
    "        data={\n",
    "            \"x\": point_cloud[:, 0],\n",
    "            \"y\": point_cloud[:, 1],\n",
    "            \"z\": point_cloud[:, 2],\n",
    "            \"label\": labels,\n",
    "        }\n",
    "    )\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    ax = plt.axes(projection=\"3d\")\n",
    "    for index, label in enumerate(LABELS):\n",
    "        c_df = df[df[\"label\"] == label]\n",
    "        try:\n",
    "            ax.scatter(\n",
    "                c_df[\"x\"], c_df[\"y\"], c_df[\"z\"], label=label, alpha=0.5, c=COLORS[index]\n",
    "            )\n",
    "        except IndexError:\n",
    "            pass\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_data(point_clouds[0], all_labels[0])\n",
    "visualize_data(point_clouds[300], all_labels[300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Preprocessing\n",
    "\n",
    "Note that all the point clouds that we have loaded consist of a variable number of points,\n",
    "which makes it difficult for us to batch them together. In order to overcome this problem, we\n",
    "randomly sample a fixed number of points from each point cloud. We also normalize the\n",
    "point clouds in order to make the data scale-invariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "for index in tqdm(range(len(point_clouds))):\n",
    "    current_point_cloud = point_clouds[index]\n",
    "    current_label_cloud = point_cloud_labels[index]\n",
    "    current_labels = all_labels[index]\n",
    "    num_points = len(current_point_cloud)\n",
    "    # Randomly sampling respective indices.\n",
    "    sampled_indices = random.sample(list(range(num_points)), NUM_SAMPLE_POINTS)\n",
    "    # Sampling points corresponding to sampled indices.\n",
    "    sampled_point_cloud = np.array([current_point_cloud[i] for i in sampled_indices])\n",
    "    # Sampling corresponding one-hot encoded labels.\n",
    "    sampled_label_cloud = np.array([current_label_cloud[i] for i in sampled_indices])\n",
    "    # Sampling corresponding labels for visualization.\n",
    "    sampled_labels = np.array([current_labels[i] for i in sampled_indices])\n",
    "    # Normalizing sampled point cloud.\n",
    "    norm_point_cloud = sampled_point_cloud - np.mean(sampled_point_cloud, axis=0)\n",
    "    norm_point_cloud /= np.max(np.linalg.norm(norm_point_cloud, axis=1))\n",
    "    point_clouds[index] = norm_point_cloud\n",
    "    point_cloud_labels[index] = sampled_label_cloud\n",
    "    all_labels[index] = sampled_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's visualize the sampled and normalized point clouds along with their corresponding\n",
    "labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "visualize_data(point_clouds[0], all_labels[0])\n",
    "visualize_data(point_clouds[300], all_labels[300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Creating TensorFlow datasets\n",
    "\n",
    "We create `tf.data.Dataset` objects for the training and validation data.\n",
    "We also augment the training point clouds by applying random jitter to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_data(point_cloud_batch, label_cloud_batch):\n",
    "    point_cloud_batch.set_shape([NUM_SAMPLE_POINTS, 3])\n",
    "    label_cloud_batch.set_shape([NUM_SAMPLE_POINTS, len(LABELS) + 1])\n",
    "    return point_cloud_batch, label_cloud_batch\n",
    "\n",
    "\n",
    "def augment(point_cloud_batch, label_cloud_batch):\n",
    "    noise = tf.random.uniform(\n",
    "        tf.shape(label_cloud_batch), -0.005, 0.005, dtype=tf.float64\n",
    "    )\n",
    "    point_cloud_batch += noise[:, :, :3]\n",
    "    return point_cloud_batch, label_cloud_batch\n",
    "\n",
    "\n",
    "def generate_dataset(point_clouds, label_clouds, is_training=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((point_clouds, label_clouds))\n",
    "    dataset = dataset.shuffle(BATCH_SIZE * 100) if is_training else dataset\n",
    "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size=BATCH_SIZE)\n",
    "    dataset = (\n",
    "        dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        if is_training\n",
    "        else dataset\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "\n",
    "split_index = int(len(point_clouds) * (1 - VAL_SPLIT))\n",
    "train_point_clouds = point_clouds[:split_index]\n",
    "train_label_cloud = point_cloud_labels[:split_index]\n",
    "total_training_examples = len(train_point_clouds)\n",
    "\n",
    "val_point_clouds = point_clouds[split_index:]\n",
    "val_label_cloud = point_cloud_labels[split_index:]\n",
    "\n",
    "print(\"Num train point clouds:\", len(train_point_clouds))\n",
    "print(\"Num train point cloud labels:\", len(train_label_cloud))\n",
    "print(\"Num val point clouds:\", len(val_point_clouds))\n",
    "print(\"Num val point cloud labels:\", len(val_label_cloud))\n",
    "\n",
    "train_dataset = generate_dataset(train_point_clouds, train_label_cloud)\n",
    "val_dataset = generate_dataset(val_point_clouds, val_label_cloud, is_training=False)\n",
    "\n",
    "print(\"Train Dataset:\", train_dataset)\n",
    "print(\"Validation Dataset:\", val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## PointNet model\n",
    "\n",
    "The figure below depicts the internals of the PointNet model family:\n",
    "\n",
    "![](https://i.imgur.com/qFLNw5L.png)\n",
    "\n",
    "Given that PointNet is meant to consume an ***unordered set*** of coordinates as its input data,\n",
    "its architecture needs to match the following characteristic properties\n",
    "of point cloud data:\n",
    "\n",
    "### Permutation invariance\n",
    "\n",
    "Given the unstructured nature of point cloud data, a scan made up of `n` points has `n!`\n",
    "permutations. The subsequent data processing must be invariant to the different\n",
    "representations. In order to make PointNet invariant to input permutations, we use a\n",
    "symmetric function (such as max-pooling) once the `n` input points are mapped to\n",
    "higher-dimensional space. The result is a **global feature vector** that aims to capture\n",
    "an aggregate signature of the `n` input points. The global feature vector is used alongside\n",
    "local point features for segmentation.\n",
    "\n",
    "![](https://i.imgur.com/0mrvvjb.png)\n",
    "\n",
    "### Transformation invariance\n",
    "\n",
    "Segmentation outputs should be unchanged if the object undergoes certain transformations,\n",
    "such as translation or scaling. For a given input point cloud, we apply an appropriate\n",
    "rigid or affine transformation to achieve pose normalization. Because each of the `n` input\n",
    "points are represented as a vector and are mapped to the embedding spaces independently,\n",
    "applying a geometric transformation simply amounts to matrix multiplying each point with\n",
    "a transformation matrix. This is motivated by the concept of\n",
    "[Spatial Transformer Networks](https://arxiv.org/abs/1506.02025).\n",
    "\n",
    "The operations comprising the T-Net are motivated by the higher-level architecture of\n",
    "PointNet. MLPs (or fully-connected layers) are used to map the input points independently\n",
    "and identically to a higher-dimensional space; max-pooling is used to encode a global\n",
    "feature vector whose dimensionality is then reduced with fully-connected layers. The\n",
    "input-dependent features at the final fully-connected layer are then combined with\n",
    "globally trainable weights and biases, resulting in a 3-by-3 transformation matrix.\n",
    "\n",
    "![](https://i.imgur.com/aEj3GYi.png)\n",
    "\n",
    "### Point interactions\n",
    "\n",
    "The interaction between neighboring points often carries useful information (i.e., a\n",
    "single point should not be treated in isolation). Whereas classification need only make\n",
    "use of global features, segmentation must be able to leverage local point features along\n",
    "with global point features.\n",
    "\n",
    "\n",
    "**Note**: The figures presented in this section have been taken from the\n",
    "[original paper](https://arxiv.org/abs/1612.00593)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Now that we know the pieces that compose the PointNet model, we can implement the model.\n",
    "We start by implementing the basic blocks i.e., the convolutional block and the multi-layer\n",
    "perceptron block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def conv_block(x: tf.Tensor, filters: int, name: str) -> tf.Tensor:\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\", name=f\"{name}_conv\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0, name=f\"{name}_batch_norm\")(x)\n",
    "    return layers.Activation(\"relu\", name=f\"{name}_relu\")(x)\n",
    "\n",
    "\n",
    "def mlp_block(x: tf.Tensor, filters: int, name: str) -> tf.Tensor:\n",
    "    x = layers.Dense(filters, name=f\"{name}_dense\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0, name=f\"{name}_batch_norm\")(x)\n",
    "    return layers.Activation(\"relu\", name=f\"{name}_relu\")(x)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We implement a regularizer (taken from\n",
    "[this example](https://keras.io/examples/vision/pointnet/#build-a-model))\n",
    "to enforce orthogonality in the feature space. This is needed to ensure\n",
    "that the magnitudes of the transformed features do not vary too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "    \"\"\"Reference: https://keras.io/examples/vision/pointnet/#build-a-model\"\"\"\n",
    "\n",
    "    def __init__(self, num_features, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.identity = tf.eye(num_features)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.identity))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(TransformerEncoder, self).get_config()\n",
    "        config.update({\"num_features\": self.num_features, \"l2reg_strength\": self.l2reg})\n",
    "        return config\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The next piece is the transformation network which we explained earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def transformation_net(inputs: tf.Tensor, num_features: int, name: str) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Reference: https://keras.io/examples/vision/pointnet/#build-a-model.\n",
    "\n",
    "    The `filters` values come from the original paper:\n",
    "    https://arxiv.org/abs/1612.00593.\n",
    "    \"\"\"\n",
    "    x = conv_block(inputs, filters=64, name=f\"{name}_1\")\n",
    "    x = conv_block(x, filters=128, name=f\"{name}_2\")\n",
    "    x = conv_block(x, filters=1024, name=f\"{name}_3\")\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = mlp_block(x, filters=512, name=f\"{name}_1_1\")\n",
    "    x = mlp_block(x, filters=256, name=f\"{name}_2_1\")\n",
    "    return layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=keras.initializers.Constant(np.eye(num_features).flatten()),\n",
    "        activity_regularizer=OrthogonalRegularizer(num_features),\n",
    "        name=f\"{name}_final\",\n",
    "    )(x)\n",
    "\n",
    "\n",
    "def transformation_block(inputs: tf.Tensor, num_features: int, name: str) -> tf.Tensor:\n",
    "    transformed_features = transformation_net(inputs, num_features, name=name)\n",
    "    transformed_features = layers.Reshape((num_features, num_features))(\n",
    "        transformed_features\n",
    "    )\n",
    "    return layers.Dot(axes=(2, 1), name=f\"{name}_mm\")([inputs, transformed_features])\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Finally, we piece the above blocks together and implement the segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_shape_segmentation_model(num_points: int, num_classes: int) -> keras.Model:\n",
    "    input_points = keras.Input(shape=(None, 3))\n",
    "\n",
    "    # PointNet Classification Network.\n",
    "    transformed_inputs = transformation_block(\n",
    "        input_points, num_features=3, name=\"input_transformation_block\"\n",
    "    )\n",
    "    features_64 = conv_block(transformed_inputs, filters=64, name=\"features_64\")\n",
    "    features_128_1 = conv_block(features_64, filters=128, name=\"features_128_1\")\n",
    "    features_128_2 = conv_block(features_128_1, filters=128, name=\"features_128_2\")\n",
    "    transformed_features = transformation_block(\n",
    "        features_128_2, num_features=128, name=\"transformed_features\"\n",
    "    )\n",
    "    features_512 = conv_block(transformed_features, filters=512, name=\"features_512\")\n",
    "    features_2048 = conv_block(features_512, filters=2048, name=\"pre_maxpool_block\")\n",
    "    global_features = layers.MaxPool1D(pool_size=num_points, name=\"global_features\")(\n",
    "        features_2048\n",
    "    )\n",
    "    global_features = tf.tile(global_features, [1, num_points, 1])\n",
    "\n",
    "    # Segmentation head.\n",
    "    segmentation_input = layers.Concatenate(name=\"segmentation_input\")(\n",
    "        [\n",
    "            features_64,\n",
    "            features_128_1,\n",
    "            features_128_2,\n",
    "            transformed_features,\n",
    "            features_512,\n",
    "            global_features,\n",
    "        ]\n",
    "    )\n",
    "    segmentation_features = conv_block(\n",
    "        segmentation_input, filters=128, name=\"segmentation_features\"\n",
    "    )\n",
    "    outputs = layers.Conv1D(\n",
    "        num_classes, kernel_size=1, activation=\"softmax\", name=\"segmentation_head\"\n",
    "    )(segmentation_features)\n",
    "    return keras.Model(input_points, outputs)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dataset))\n",
    "\n",
    "num_points = x.shape[1]\n",
    "num_classes = y.shape[-1]\n",
    "\n",
    "segmentation_model = get_shape_segmentation_model(num_points, num_classes)\n",
    "segmentation_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Training\n",
    "\n",
    "For the training the authors recommend using a learning rate schedule that decays the\n",
    "initial learning rate by half every 20 epochs. In this example, we resort to 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "training_step_size = total_training_examples // BATCH_SIZE\n",
    "total_training_steps = training_step_size * EPOCHS\n",
    "print(f\"Total training steps: {total_training_steps}.\")\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[training_step_size * 15, training_step_size * 15],\n",
    "    values=[INITIAL_LR, INITIAL_LR * 0.5, INITIAL_LR * 0.25],\n",
    ")\n",
    "\n",
    "steps = tf.range(total_training_steps, dtype=tf.int32)\n",
    "lrs = [lr_schedule(step) for step in steps]\n",
    "\n",
    "plt.plot(lrs)\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Finally, we implement a utility for running our experiments and launch model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_experiment(epochs):\n",
    "\n",
    "    segmentation_model = get_shape_segmentation_model(num_points, num_classes)\n",
    "    segmentation_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss=keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = segmentation_model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=epochs,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    segmentation_model.load_weights(checkpoint_filepath)\n",
    "    return segmentation_model, history\n",
    "\n",
    "\n",
    "segmentation_model, history = run_experiment(epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Visualize the training landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_result(item):\n",
    "    plt.plot(history.history[item], label=item)\n",
    "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(item)\n",
    "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_result(\"loss\")\n",
    "plot_result(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "validation_batch = next(iter(val_dataset))\n",
    "val_predictions = segmentation_model.predict(validation_batch[0])\n",
    "print(f\"Validation prediction shape: {val_predictions.shape}\")\n",
    "\n",
    "\n",
    "def visualize_single_point_cloud(point_clouds, label_clouds, idx):\n",
    "    label_map = LABELS + [\"none\"]\n",
    "    point_cloud = point_clouds[idx]\n",
    "    label_cloud = label_clouds[idx]\n",
    "    visualize_data(point_cloud, [label_map[np.argmax(label)] for label in label_cloud])\n",
    "\n",
    "\n",
    "idx = np.random.choice(len(validation_batch[0]))\n",
    "print(f\"Index selected: {idx}\")\n",
    "\n",
    "# Plotting with ground-truth.\n",
    "visualize_single_point_cloud(validation_batch[0], validation_batch[1], idx)\n",
    "\n",
    "# Plotting with predicted labels.\n",
    "visualize_single_point_cloud(validation_batch[0], val_predictions, idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Final notes\n",
    "\n",
    "If you are interested in learning more about this topic, you may find\n",
    "[this repository](https://github.com/soumik12345/point-cloud-segmentation)\n",
    "useful."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pointnet_segmentation",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}