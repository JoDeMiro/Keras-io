{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Consistency training with supervision\n",
    "\n",
    "**Author:** [Sayak Paul](https://twitter.com/RisingSayak)<br>\n",
    "**Date created:** 2021/04/13<br>\n",
    "**Last modified:** 2021/04/19<br>\n",
    "**Description:** Training with consistency regularization for robustness against data distribution shifts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Deep learning models excel in many image recognition tasks when the data is independent\n",
    "and identically distributed (i.i.d.). However, they can suffer from performance\n",
    "degradation caused by subtle distribution shifts in the input data  (such as random\n",
    "noise, contrast change, and blurring). So, naturally, there arises a question of\n",
    "why. As discussed in [A Fourier Perspective on Model Robustness in Computer Vision](https://arxiv.org/pdf/1906.08988.pdf)),\n",
    "there's no reason for deep learning models to be robust against such shifts. Standard\n",
    "model training procedures (such as standard image classification training workflows)\n",
    "*don't* enable a model to learn beyond what's fed to it in the form of training data.\n",
    "\n",
    "In this example, we will be training an image classification model enforcing a sense of\n",
    "*consistency* inside it by doing the following:\n",
    "\n",
    "* Train a standard image classification model.\n",
    "* Train an _equal or larger_ model on a noisy version of the dataset (augmented using\n",
    "[RandAugment](https://arxiv.org/abs/1909.13719)).\n",
    "* To do this, we will first obtain predictions of the previous model on the clean images\n",
    "of the dataset.\n",
    "* We will then use these predictions and train the second model to match these\n",
    "predictions on the noisy variant of the same images. This is identical to the workflow of\n",
    "[*Knowledge Distillation*](https://keras.io/examples/vision/knowledge_distillation/) but\n",
    "since the student model is equal or larger in size this process is also referred to as\n",
    "***Self-Training***.\n",
    "\n",
    "This overall training workflow finds its roots in works like\n",
    "[FixMatch](https://arxiv.org/abs/2001.07685), [Unsupervised Data Augmentation for Consistency Training](https://arxiv.org/abs/1904.12848),\n",
    "and [Noisy Student Training](https://arxiv.org/abs/1911.04252). Since this training\n",
    "process encourages a model yield consistent predictions for clean as well as noisy\n",
    "images, it's often referred to as *consistency training* or *training with consistency\n",
    "regularization*. Although the example focuses on using consistency training to enhance\n",
    "the robustness of models to common corruptions this example can also serve a template\n",
    "for performing _weakly supervised learning_.\n",
    "\n",
    "This example requires TensorFlow 2.4 or higher, as well as TensorFlow Hub and TensorFlow\n",
    "Models, which can be installed using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!pip install -q tf-models-official tensorflow-addons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from official.vision.image_classification.augment import RandAugment\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "AUTO = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "\n",
    "CROP_TO = 72\n",
    "RESIZE_TO = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Load the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "val_samples = 49500\n",
    "new_train_x, new_y_train = x_train[: val_samples + 1], y_train[: val_samples + 1]\n",
    "val_x, val_y = x_train[val_samples:], y_train[val_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Create TensorFlow `Dataset` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Initialize `RandAugment` object with 2 layers of\n",
    "# augmentation transforms and strength of 9.\n",
    "augmenter = RandAugment(num_layers=2, magnitude=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "For training the teacher model, we will only be using two geometric augmentation\n",
    "transforms: random horizontal flip and random crop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_train(image, label, noisy=True):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # We first resize the original image to a larger dimension\n",
    "    # and then we take random crops from it.\n",
    "    image = tf.image.resize(image, [RESIZE_TO, RESIZE_TO])\n",
    "    image = tf.image.random_crop(image, [CROP_TO, CROP_TO, 3])\n",
    "    if noisy:\n",
    "        image = augmenter.distort(image)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def preprocess_test(image, label):\n",
    "    image = tf.image.resize(image, [CROP_TO, CROP_TO])\n",
    "    return image, label\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((new_train_x, new_y_train))\n",
    "validation_ds = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We make sure `train_clean_ds` and `train_noisy_ds` are shuffled using the *same* seed to\n",
    "ensure their orders are exactly the same. This will be helpful during training the\n",
    "student model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# This dataset will be used to train the first model.\n",
    "train_clean_ds = (\n",
    "    train_ds.shuffle(BATCH_SIZE * 10, seed=42)\n",
    "    .map(lambda x, y: (preprocess_train(x, y, noisy=False)), num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "# This prepares the `Dataset` object to use RandAugment.\n",
    "train_noisy_ds = (\n",
    "    train_ds.shuffle(BATCH_SIZE * 10, seed=42)\n",
    "    .map(preprocess_train, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "validation_ds = (\n",
    "    validation_ds.map(preprocess_test, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "test_ds = (\n",
    "    test_ds.map(preprocess_test, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "# This dataset will be used to train the second model.\n",
    "consistency_training_ds = tf.data.Dataset.zip((train_clean_ds, train_noisy_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Visualize the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "sample_images, sample_labels = next(iter(train_clean_ds))\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, image in enumerate(sample_images[:9]):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image.numpy().astype(\"int\"))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "sample_images, sample_labels = next(iter(train_noisy_ds))\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, image in enumerate(sample_images[:9]):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image.numpy().astype(\"int\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Define a model building utility function\n",
    "\n",
    "We now define our model building utility. Our model is based on the [ResNet50V2 architecture](https://arxiv.org/abs/1603.05027)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_training_model(num_classes=10):\n",
    "    resnet50_v2 = tf.keras.applications.ResNet50V2(\n",
    "        weights=None, include_top=False, input_shape=(CROP_TO, CROP_TO, 3),\n",
    "    )\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            layers.Input((CROP_TO, CROP_TO, 3)),\n",
    "            layers.Rescaling(scale=1.0 / 127.5, offset=-1),\n",
    "            resnet50_v2,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dense(num_classes),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "In the interest of reproducibility, we serialize the initial random weights of the\n",
    "teacher  network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "initial_teacher_model = get_training_model()\n",
    "initial_teacher_model.save_weights(\"initial_teacher_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Train the teacher model\n",
    "\n",
    "As noted in Noisy Student Training, if the teacher model is trained with *geometric\n",
    "ensembling* and when the student model is forced to mimic that, it leads to better\n",
    "performance. The original work uses [Stochastic Depth](https://arxiv.org/abs/1603.09382)\n",
    "and [Dropout](https://jmlr.org/papers/v15/srivastava14a.html) to bring in the ensembling\n",
    "part but for this example, we will use [Stochastic Weight Averaging](https://arxiv.org/abs/1803.05407)\n",
    "(SWA) which also resembles geometric ensembling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Define the callbacks.\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(patience=3)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Initialize SWA from tf-hub.\n",
    "SWA = tfa.optimizers.SWA\n",
    "\n",
    "# Compile and train the teacher model.\n",
    "teacher_model = get_training_model()\n",
    "teacher_model.load_weights(\"initial_teacher_model.h5\")\n",
    "teacher_model.compile(\n",
    "    # Notice that we are wrapping our optimizer within SWA\n",
    "    optimizer=SWA(tf.keras.optimizers.Adam()),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = teacher_model.fit(\n",
    "    train_clean_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_ds,\n",
    "    callbacks=[reduce_lr, early_stopping],\n",
    ")\n",
    "\n",
    "# Evaluate the teacher model on the test set.\n",
    "_, acc = teacher_model.evaluate(test_ds, verbose=0)\n",
    "print(f\"Test accuracy: {acc*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Define a self-training utility\n",
    "\n",
    "For this part, we will borrow the `Distiller` class from [this Keras Example](https://keras.io/examples/vision/knowledge_distillation/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Majority of the code is taken from:\n",
    "# https://keras.io/examples/vision/knowledge_distillation/\n",
    "class SelfTrainer(tf.keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super(SelfTrainer, self).__init__()\n",
    "        self.student = student\n",
    "        self.teacher = teacher\n",
    "\n",
    "    def compile(\n",
    "        self, optimizer, metrics, student_loss_fn, distillation_loss_fn, temperature=3,\n",
    "    ):\n",
    "        super(SelfTrainer, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Since our dataset is a zip of two independent datasets,\n",
    "        # after initially parsing them, we segregate the\n",
    "        # respective images and labels next.\n",
    "        clean_ds, noisy_ds = data\n",
    "        clean_images, _ = clean_ds\n",
    "        noisy_images, y = noisy_ds\n",
    "\n",
    "        # Forward pass of teacher\n",
    "        teacher_predictions = self.teacher(clean_images, training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student\n",
    "            student_predictions = self.student(noisy_images, training=True)\n",
    "\n",
    "            # Compute losses\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            total_loss = (student_loss + distillation_loss) / 2\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(total_loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update the metrics configured in `compile()`\n",
    "        self.compiled_metrics.update_state(\n",
    "            y, tf.nn.softmax(student_predictions, axis=1)\n",
    "        )\n",
    "\n",
    "        # Return a dict of performance\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"total_loss\": total_loss})\n",
    "        return results\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # During inference, we only pass a dataset consisting images and labels.\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions\n",
    "        y_prediction = self.student(x, training=False)\n",
    "\n",
    "        # Update the metrics\n",
    "        self.compiled_metrics.update_state(y, tf.nn.softmax(y_prediction, axis=1))\n",
    "\n",
    "        # Return a dict of performance\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        return results\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The only difference in this implementation is the way loss is being calculated. **Instead\n",
    "of weighted the distillation loss and student loss differently we are taking their\n",
    "average following Noisy Student Training**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Train the student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Define the callbacks.\n",
    "# We are using a larger decay factor to stabilize the training.\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    patience=3, factor=0.5, monitor=\"val_accuracy\"\n",
    ")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10, restore_best_weights=True, monitor=\"val_accuracy\"\n",
    ")\n",
    "\n",
    "# Compile and train the student model.\n",
    "self_trainer = SelfTrainer(student=get_training_model(), teacher=teacher_model)\n",
    "self_trainer.compile(\n",
    "    # Notice we are *not* using SWA here.\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    student_loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=tf.keras.losses.KLDivergence(),\n",
    "    temperature=10,\n",
    ")\n",
    "history = self_trainer.fit(\n",
    "    consistency_training_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_ds,\n",
    "    callbacks=[reduce_lr, early_stopping],\n",
    ")\n",
    "\n",
    "# Evaluate the student model.\n",
    "acc = self_trainer.evaluate(test_ds, verbose=0)\n",
    "print(f\"Test accuracy from student model: {acc*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Assess the robustness of the models\n",
    "\n",
    "A standard benchmark of assessing the robustness of vision models is to record their\n",
    "performance on corrupted datasets like ImageNet-C and CIFAR-10-C both of which were\n",
    "proposed in [Benchmarking Neural Network Robustness to Common Corruptions and\n",
    "Perturbations](https://arxiv.org/abs/1903.12261). For this example, we will be using the\n",
    "CIFAR-10-C dataset which has 19 different corruptions on 5 different severity levels. To\n",
    "assess the robustness of the models on this dataset, we will do the following:\n",
    "\n",
    "* Run the pre-trained models on the highest level of severities and obtain the top-1\n",
    "accuracies.\n",
    "* Compute the mean top-1 accuracy.\n",
    "\n",
    "For the purpose of this example, we won't be going through these steps. This is why we\n",
    "trained the models for only 5 epochs. You can check out [this\n",
    "repository](https://github.com/sayakpaul/Consistency-Training-with-Supervision) that\n",
    "demonstrates the full-scale training experiments and also the aforementioned assessment.\n",
    "The figure below presents an executive summary of that assessment:\n",
    "\n",
    "![](https://i.ibb.co/HBJkM9R/image.png)\n",
    "\n",
    "**Mean Top-1** results stand for the CIFAR-10-C dataset and **Test Top-1** results stand\n",
    "for the CIFAR-10 test set. It's clear that consistency training has an advantage on not\n",
    "only enhancing the model robustness but also on improving the standard test performance."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "consistency_training",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}